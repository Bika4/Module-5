{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pandas import Series \nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n\nfrom sklearn.metrics import confusion_matrix, auc, roc_auc_score, roc_curve\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Зададим цвета\ncolors = ['#001c57', '#50248f', '#a6a6a6', '#38d1ff','#cc3181']\nsns.palplot(sns.color_palette(colors))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sfdstscoring/train.csv')\ntest= pd.read_csv('/kaggle/input/sfdstscoring/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/sfdstscoring/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Соединим train и test в один датасет\n\ntrain['sample'] = 1  # train\ntest['sample'] = 0  # test\n\ndata = test.append(train, sort=False).reset_index(\n    drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на случайные 3 строк базы\ndisplay(data.sample(3))\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на типы данных\ndtype_data = data.dtypes.reset_index()\ndtype_data.columns = ['Count', 'Column Type']\ndtype_data.groupby('Column Type').agg('count').reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, j in enumerate(data.columns):\n    print(j, type(data.loc[1][i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Статистическая информация о базе\ndata.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unique values count, first 10 unique values, null values count, type\ndata.agg({'nunique', lambda s: s.unique()[:10]})    .append(pd.Series(data.isnull().sum(), name='null'))    .append(pd.Series(data.dtypes, name='dtype'))    .transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Датасет имеет 19 параметров, не включая sample, общее число наблюдений 110148, есть пропуски в education - 478 и default - 36349. При этом education содержит 5 уникальных значений client_id полностью содержит только уникальные значения, можно сказать что нет дубликатов. В целом датасет содержит числовые, бинарные и категориальные признаки. default - наша целевая переменная.","metadata":{}},{"cell_type":"markdown","source":"Подробнее по признакам:\n* client_id - идентификатор клиента\n* education - уровень образования\n* sex - пол заемщика\n* age - возраст заемщика\n* car - флаг наличия автомобиля\n* car_type - флаг автомобиля иномарки\n* decline_app_cnt - количество отказанных прошлых заявок\n* good_work - флаг наличия “хорошей” работы\n* bki_request_cnt - количество запросов в БКИ\n* home_address - категоризатор домашнего адреса\n* work_address - категоризатор рабочего адреса\n* income - доход заемщика\n* foreign_passport - наличие загранпаспорта\n* sna - связь заемщика с клиентами банка\n* first_time - давность наличия информации о заемщике\n* score_bki - скоринговый балл по данным из БКИ\n* region_rating - рейтинг региона\n* app_date - дата подачи заявки\n* default - флаг дефолта по кредиту","metadata":{}},{"cell_type":"code","source":"# Посмотрим на первые 10 строк sample_submission\nsample_submission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предобработка данных","metadata":{}},{"cell_type":"code","source":"# Количество пропусков в обучающей базе\ntrain.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Количество пропусков в тестовой базе\ntest.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Гистограмма значений признака education, содержащего пропуски, в обучающей базе\ntrain.education.value_counts().plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Гистограмма значений признака education, содержащего пропуски, в тестовой базе\ntest.education.value_counts().plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Избавление от пропусков\n# заполним пропуски на наиболее часто встречающееся значение SCH\ntrain.education.fillna('SCH', inplace = True)\ntest.education.fillna('SCH', inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на целевую переменную\nsns.countplot(train['default'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Распределение заёмщиков явно неравномерное, недефолтных клиентов заметно больше.","metadata":{}},{"cell_type":"code","source":"# попробуем oversampling для устранения дисбаланса\ntrain_0 = train.query('default == 0')\ntrain_1 = train.query('default == 1')\nkoeff = int(len(train_0)/len(train_1))\nfor i in range(koeff):\n    train = train.append(train_1).reset_index(drop=True)  # объединяем","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на целевую переменную после\nsns.countplot(train['default'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выведем наименования всех признаков обучающей базы\ntrain.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сгруппируем признаки для упрощения обработки.","metadata":{}},{"cell_type":"code","source":"target = 'default'\n# числовые переменные\nnum_cols = ['age', 'decline_app_cnt', 'bki_request_cnt', 'income', 'score_bki', 'region_rating']\n\n# категориальные переменные\ncat_cols = ['education', 'work_address', 'home_address', 'sna', 'first_time']\n\n# бинарные переменные\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Числовые признаки","metadata":{}},{"cell_type":"code","source":"# Посмотрим на распределение числовых признаков.\ndef get_num_info(col, title=None):\n    '''Function is called to plot feture distribution'''\n\n    title = title if title is not None else f\"Distribution for '{col}\"\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5),)\n    fig = sm.qqplot(col, fit=True, line='45', ax=ax1)\n    fig.suptitle(title, fontsize=20)\n\n    sns.distplot(col.values, bins=20, color=colors[1], ax=ax2)\n    sns.violinplot(col.values, color=colors[3], bw=.3, cut=1, linewidth=4)\n\n    ax1.set_title('QQ-plot')\n    ax2.set_title('Distribution')\n    ax3.set_title('Violinplot')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(data):\n    '''Function is called to detect outliers'''\n    q1, q3 = np.percentile(sorted(data), [25, 75])\n\n    IQR = q3 - q1\n\n    l_b = q1 - (1.5 * IQR) # lower bound\n    u_b = q3 + (1.5 * IQR) # upper bound\n    outl_count = len(data[data < l_b]) + len(data[data > u_b])\n\n    print(\n        f'Lower Bound: {round(l_b,3)}, Upper Bound {round(u_b,3)}, Outliers Count: {outl_count}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in num_cols:\n    get_num_info(train[col], title=col)\n    detect_outliers(train[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"После построения графиков стало очевидно, что только score_bki имеет распределение близкое к нормальному остальные числовых переменные имеют тяжёлый правый хвост, кроме region_rating.","metadata":{}},{"cell_type":"code","source":"# Посмотрим на тепловую карту числовых признаков\nsns.heatmap(train[num_cols].corr().abs(), vmin=0, vmax=1, annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Наибольшая положительная корреляция наблюдается у дохода, затем чуть меньше у количества отказов, что объясняется правилами выдачи кредитов. Но в целом численные признаки скоррелированы слабо.","metadata":{}},{"cell_type":"code","source":"# Проверим теперь значимость числовых признаков\nimp_num = pd.Series(f_classif(train[num_cols], train['default'])[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Здесь заметим, что большее значение имеют скоринговый балл по данным из БКИ и количество отказов, в меньшей степени возраст и что удивительно доход также не является наиболее важным значением.","metadata":{}},{"cell_type":"markdown","source":"# Бинарные и категориальные признаки","metadata":{}},{"cell_type":"code","source":"class Preprocessing:\n    def __init__(self, data):\n        self.data = data\n\n    def label_encoder(self, column):\n        le = LabelEncoder()\n        self.data[column] = le.fit_transform(self.data[column])\n\n    def hot_enc(self, column):\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        aux_df = pd.DataFrame(ohe.fit_transform(self.data[[column]]))\n        aux_df.columns = ohe.get_feature_names([f'hot_{column}'])\n        self.data = self.data.drop(col, axis=1)\n        self.data = pd.concat([self.data, aux_df], axis=1)\n        return self.data \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создадим пример класса для тренингового сета\nencoder = Preprocessing(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in bin_cols:\n    encoder.label_encoder(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_bol = pd.Series(mutual_info_classif(train[bin_cols], train['default'],\n                                        discrete_features=True), index=[bin_cols])\nimp_bol.sort_values(inplace=True)\nimp_bol.plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Самый важные параметры для целевой переменной - наличие загран паспорта и тип машины","metadata":{}},{"cell_type":"code","source":"# создадим пример класса для тестового сета \nencoder = Preprocessing(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in bin_cols:\n    encoder.label_encoder(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# убедимся в преобразовании\ndisplay(train.head())\ndisplay(test.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_boxplot(data, col1, col2, hue=None):\n    '''Function is called to plot boxplots'''\n    fig, ax = plt.subplots(figsize=(7, 5))\n    sns.boxplot(x=col1, y=col2, hue=hue, data=data, palette=colors)\n    plt.xticks(rotation=45)\n    ax.set_title(f'Boxplot for {col1} and {col2}', fontsize=14)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_boxplot(train, 'education', 'sna', hue='default')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Здесь наблюдается связь между образованием заемщиков и клиентами банка. Как мы видим менее образованные заемщики имеют большую связь с другими клиентами. Может больше кредитов берут из одного коллектива, типа завод и т.п.","metadata":{}},{"cell_type":"code","source":"# Заменим значения признака education числами в обеих базах: на 1 - школьное и 0 - высшее\neducation_dict = {'ACD': 0, 'PGR': 0, 'UGR': 0, 'GRD': 0, 'SCH': 1}\ntrain.education = train['education'].map(education_dict)\n\ntrain.education.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Заменим значения признака education числами в тестовой базе\ntest.education = test['education'].map(education_dict)\n\ntest.education.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Используем encoder для категориальных признаков для лучшей интерпретации.\nfor col in cat_cols:\n    encoder.label_encoder(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_cat = pd.Series(mutual_info_classif(train[cat_cols], train['default'],\n                                        discrete_features=True), index=[cat_cols])\nimp_cat.sort_values(inplace=True)\nimp_cat.plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на тепловую карту категириальных признаков\nsns.heatmap(train[cat_cols].corr().abs(), vmin=0, vmax=1, annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Наибольшая корреляция между дом и раб адресами, чуть меньше между sna & first_time. Но все равно не больше 0.8 поэтому ничего делать не будем.","metadata":{}},{"cell_type":"markdown","source":"# Дата","metadata":{}},{"cell_type":"code","source":"# Взглянем поближе на признак app_date\ntrain.app_date.head(5), test.app_date.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сконветируем в более удобный формат даты\ntrain.app_date = pd.to_datetime(train.app_date)\ntest.app_date = pd.to_datetime(test.app_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим количество уникальных годов в признаке app_date обучающей базы\ntrain.app_date.apply(lambda x: x.year).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим количество уникальных годов в признаке app_date тестовой базы\ntest.app_date.apply(lambda x: x.year).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим количество уникальных месяцев в признаке app_date обучающей базы\ntrain.app_date.apply(lambda x: x.month).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим количество уникальных месяцев в признаке app_date тестовой базы\ntest.app_date.apply(lambda x: x.month).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Добавление новых признаков (Feature engineering)","metadata":{}},{"cell_type":"code","source":"# Новый признак месяца подачи заявления на кредит\ntrain['month'] = train.app_date.apply(lambda x: x.month)\ntest['month'] = train.app_date.apply(lambda x: x.month)\n\ncat_cols.append('month')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Новый признак количество дней между датой подачи заявления на кредит и датой первой подачи в базе\ntrain['days'] = (train.app_date - train.app_date.min()).dt.days\ntest['days'] = (test.app_date - test.app_date.min()).dt.days\n\nnum_cols.append('days')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прологарифмируем переменные, распределение которых смещено\nnum_cols_log = ['age', 'bki_request_cnt', 'income', 'decline_app_cnt']\n\nfor i in num_cols_log:\n    train[i] = np.log(train[i] + 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols_log:\n    test[i] = np.log(test[i] + 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавим новые признаки, на основе существующих, которые должны будут улучшить результаты модели\ntrain['bki_age_reg'] = (train['score_bki']/train['age'])*train['region_rating']\ntest['bki_age_reg'] = (test['score_bki']/test['age'])*test['region_rating']\n\ntrain['mult_sna_ftime'] = train['sna'] * train['first_time']\ntest['mult_sna_ftime'] = test['sna'] * test['first_time']\n\ntrain['edu_and_income'] = (train['education'] + 1) * train['income']\ntest['edu_and_income'] = (test['education'] + 1) * test['income']\n\ntrain['success_client'] = (train['foreign_passport'] + 1) * (train['good_work'] + 1) * (train['car'] + 1)\ntest['success_client'] = (test['foreign_passport'] + 1) * (test['good_work'] + 1) * (test['car'] + 1)\n\ntrain['very_success_client'] = train['foreign_passport'] * train['good_work'] * train['car']\ntest['very_success_client'] = test['foreign_passport'] * test['good_work'] * test['car']\n\ntrain['fpassp_and_gwork'] = train['foreign_passport'] * train['good_work'] \ntest['fpassp_and_gwork'] = test['foreign_passport'] * test['good_work']\n\ntrain['fpassp_and_car'] = train['foreign_passport'] * train['car']\ntest['fpassp_and_car'] = test['foreign_passport'] * test['car']\n\ntrain['gwork_and_car'] = train['good_work'] * train['car']\ntest['gwork_and_car'] = test['good_work'] * test['car']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавляем новые признаки в соответствующие списки\nnum_cols.append('bki_age_reg')\nnum_cols.append('mult_sna_ftime')\nnum_cols.append('edu_and_income')\ncat_cols.append('success_client')\nbin_cols.append('very_success_client')\nbin_cols.append('fpassp_and_gwork')\nbin_cols.append('fpassp_and_car')\nbin_cols.append('gwork_and_car')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# посмотрим на информацию по базам после изменений  \ntrain.info()\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на распределение значений decline_app_cnt в обучающей выборке\ntrain.decline_app_cnt.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# изменим значения признака decline_app_cnt, которые встречаются наиболее редко, единственным значением\ntrain['decline_app_cnt'] = train['decline_app_cnt'].apply(lambda x: x if x < 4 else 4)\ntest['decline_app_cnt'] = test['decline_app_cnt'].apply(lambda x: x if x < 4 else 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Изменяем принадлежность к списку признаку decline_app_cnt\nnum_cols.remove('decline_app_cnt')\ncat_cols.append('decline_app_cnt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Визуализация и значимость признаков","metadata":{}},{"cell_type":"code","source":"# Посмотрим на гистограммы распределения бинарных признаков\nfor column in bin_cols:\n    plt.figure()\n    sns.countplot(train[column])\n    plt.title(column)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Бинарные признаки распределены не равномерно, но мы выровняли распределение только по целевой переменной, тут мы ничего делать не будем.","metadata":{}},{"cell_type":"code","source":"# boxplots числовых признаков\nfor column in num_cols:\n    plt.figure()\n    sns.boxplot(x=train['default'], y=train[column])\n    plt.title(column)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Есть выбросы. Попробуем некоторые исправить.","metadata":{}},{"cell_type":"code","source":"# Функция определяет межквартильный интервал и возвращает 1.5 межквартильных расстояния с обеих\n# сторон от этого интервала. С её помощью избавимся от выбросов.\n\ndef outliers_iqr(ys):\n    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n    iqr = quartile_3 - quartile_1\n    lower_bound = quartile_1 - (iqr * 1.5)\n    upper_bound = quartile_3 + (iqr * 1.5)\n    return lower_bound, upper_bound","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Значимость бинарных и категориальных переменных\nimp_cat = Series(mutual_info_classif(train[bin_cols + cat_cols], train['default'],\n                                     discrete_features =True), index = bin_cols + cat_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# еще раз посмотрим на значимость числовых переменных\nimp_num = Series(f_classif(train[num_cols], train['default'])[0],\n                 index=num_cols)\nimp_num.sort_values(inplace=True)\nimp_num.plot(kind='barh')\nplt.xlabel('F-value')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corr_matrix(data, det=True, pltx=10, plty=10):\n    '''Funcion is called for making correlation matrix'''\n    \n    X = data.corr()\n    if det:\n        \n        evals,evec = np.linalg.eig(X)\n        ev_product = np.prod(evals)\n    \n        print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n        print(f'Determinant of matrix: {np.round(ev_product,4)}')\n        print(f'Shape of matrix: {np.shape(X)}')\n    \n    plt.figure(figsize=(pltx,plty))\n    sns.heatmap(X,vmin=0,vmax=.9,annot=True,square=True)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# посмотрим на корреляцию признаков обучающей базы\ncorr_matrix(train.drop(['sample'], axis=1), det=False, pltx=20, plty=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Признаки с высокой корреляцией удалим (выше 0.8 по модулю)\ncat_cols.remove('month')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка модели","metadata":{}},{"cell_type":"code","source":"X_cat = OneHotEncoder(sparse = False).fit_transform(train[cat_cols].values)\nX_cat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_cat = OneHotEncoder(sparse = False).fit_transform(test[cat_cols].values)\nY_cat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Стандартизация числовых непрерывных переменных на обучающей базе\n\nX_num = StandardScaler().fit_transform(train[num_cols].values)\nX_num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Стандартизация числовых непрерывных переменных на тестовой базе\n\nY_num = StandardScaler().fit_transform(test[num_cols].values)\nY_num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Объединяем\n\nX = np.hstack([X_num, train[bin_cols].values, X_cat])\nY = train['default'].values\n\nid_test = test['client_id']\ntest = np.hstack([Y_num, test[bin_cols].values, Y_cat])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Разделяем обучающую выборку на тренировочную и валидационную\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подбор лучших гиперпараметров для модели\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Добавим типы регуляризации\npenalty = ['l1', 'l2']\n\n# Зададим ограничения для параметра регуляризации\nC = np.logspace(0, 4, 10)\n\n# Создадим гиперпараметры\nhyperparameters = dict(C=C, penalty=penalty)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Создаем сетку поиска с использованием 5-кратной перекрестной проверки\nclf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n\nbest_model = clf.fit(X_train, y_train)\n\nprint('Лучшее Penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('Лучшее C:', best_model.best_estimator_.get_params()['C'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Описываем и обучаем модель\nmodel = LogisticRegression( \n                           C=2.7825594022071245, \n                           class_weight='balanced', \n                           dual=False, \n                           fit_intercept=True, \n                           intercept_scaling=1, \n                           l1_ratio=None, \n                           multi_class='auto', \n                           n_jobs=None, \n                           penalty='l2', \n                           solver='liblinear', \n                           verbose=0, \n                           max_iter=1000)\n\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Предсказываем значения валидационной базы\nY_predict = model.predict(X_valid)\nY_predict_prob = model.predict_proba(X_valid)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Предсказываем значения тестовой базы\ny_pred_test = model.predict(test)\ny_pred_prob_test = model.predict_proba(test)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предварительные результаты","metadata":{}},{"cell_type":"code","source":"# Строим ROC-кривую\nfpr, tpr, threshold = roc_curve(y_valid, Y_predict_prob)\nroc_auc = roc_auc_score(y_valid, Y_predict_prob)\n\nplt.figure()\nplt.plot([0, 1], label='Baseline', linestyle='--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Функция для визуализации confusion_matrix\ndef show_confusion_matrix(y_true, y_pred):\n    color_text = plt.get_cmap('PuBu')(0.95)\n    class_names = ['Default', 'Non-Default']\n    cm = confusion_matrix(y_true, y_pred)\n    cm[0,0], cm[1,1] = cm[1,1], cm[0,0]\n    df = pd.DataFrame(cm, index=class_names, columns=class_names)\n    \n    fig, ax = plt.subplots(figsize=(6, 6))\n    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), title=\"Confusion Matrix\")\n    ax.title.set_fontsize(15)\n    sns.heatmap(df, square=True, annot=True, fmt=\"d\", linewidths=1, cmap=\"PuBu\")\n    plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)\n    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\", rotation_mode=\"anchor\", fontsize=12)\n    ax.set_ylabel('Predicted Values', fontsize=14, color = color_text)\n    ax.set_xlabel('Real Values', fontsize=14, color = color_text)\n    b, t = plt.ylim()\n    plt.ylim(b+0.5, t-0.5)\n    fig.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выведем confusion_matrix\nshow_confusion_matrix(y_valid, Y_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Функция для вывода метрик для оценки качества модели\ndef all_metrics(y_true, y_pred, y_pred_prob):\n    dict_metric = {}\n    P = np.sum(y_true==1)\n    N = np.sum(y_true==0)\n    TP = np.sum((y_true==1)&(y_pred==1))\n    TN = np.sum((y_true==0)&(y_pred==0))\n    FP = np.sum((y_true==0)&(y_pred==1))\n    FN = np.sum((y_true==1)&(y_pred==0))\n    \n    dict_metric['Positive, P'] = [P,'default']\n    dict_metric['Negative, N'] = [N,'non-default']\n    dict_metric['True Positive, TP'] = [TP,'correctly identified default']\n    dict_metric['True Negative, TN'] = [TN,'correctly identified non-default']\n    dict_metric['False Positive, FP'] = [FP,'incorrectly identified default']\n    dict_metric['False Negative, FN'] = [FN,'incorrectly identified non-default']\n    dict_metric['Accuracy'] = [accuracy_score(y_true, y_pred),'Accuracy=(TP+TN)/(P+N)']\n    dict_metric['Precision'] = [precision_score(y_true, y_pred),'Precision = TP/(TP+FP)'] \n    dict_metric['Recall'] = [recall_score(y_true, y_pred),'Recall = TP/P']\n    dict_metric['F1-score'] = [f1_score(y_true, y_pred),'Harmonical mean of Precision и Recall']\n    dict_metric['ROC_AUC'] = [roc_auc_score(y_true, y_pred_prob),'ROC AUC Score']    \n\n    temp_df = pd.DataFrame.from_dict(dict_metric, orient='index', columns=['Value', 'Description'])\n    display(temp_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выведем метрики качества модели\nall_metrics(y_valid, Y_predict, Y_predict_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем модель на всей обучающей базе\nmain_model = LogisticRegression( \n                           C=2.7825594022071245, \n                           class_weight='balanced', \n                           dual=False, \n                           fit_intercept=True, \n                           intercept_scaling=1, \n                           l1_ratio=None, \n                           multi_class='auto', \n                           n_jobs=None, \n                           penalty='l2', \n                           solver='liblinear', \n                           verbose=0, \n                           max_iter=1000)\nmain_model.fit(X, Y)\n\n# Предсказываем значения тестовой базы\ny_pred_test = main_model.predict(test)\ny_pred_prob_test = main_model.predict_proba(test)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Записываем предсказанные моделью вероятности дефолта заемщиков из тестовой базы в отдельный файл\nnew_sample_submission = pd.DataFrame({'client_id': id_test,\n                              'default': y_pred_prob_test})\nnew_sample_submission.to_csv('submission.csv', index=False)\n\nnew_sample_submission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}